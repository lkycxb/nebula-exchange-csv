# Use the command to submit the exchange job:

# spark-submit \
# --master "spark://master_ip:7077" \
# --driver-memory=2G --executor-memory=30G  \
# --num-executors=3 --executor-cores=20 \
# --class com.vesoft.nebula.exchange.Exchange \
# nebula-exchange-3.0-SNAPSHOT.jar -c csv_datasource.conf

{
  # Spark config
  spark: {
    app: {
      name: NebulaGraph Exchange
    }
  }

  # Nebula Graph config
  nebula: {
    address:{
      graph:["192.88.1.241:9669"]
      # if your NebulaGraph server is in virtual network like k8s, please config the leader address of meta.
      # use `SHOW meta leader` to see your meta leader's address
      meta:["192.88.1.241:9559"]
    }
    user: root
    pswd: nebula
    space: compographtest

    path:{
        # any path that owns read and write access is ok
        local:"F:/share/vulncomponents/nebula/compograph/local"
        #remote:"F:/share/vulncomponents/nebula/compograph/sst/compo"
        hdfs.namenode: "file:///"
    }

    # nebula client connection parameters
    connection {
      # socket connect & execute timeout, unit: millisecond
      timeout: 30000
    }

    error: {
      # max number of failures, if the number of failures is bigger than max, then exit the application.
      max: 32
      # failed data will be recorded in output path, format with ngql
      output: /tmp/errors
    }

    # use google's RateLimiter to limit the requests send to NebulaGraph
    rate: {
      # the stable throughput of RateLimiter
      limit: 1024
      # Acquires a permit from RateLimiter, unit: MILLISECONDS
      # if it can't be obtained within the specified timeout, then give up the request.
      timeout: 1000
    }
  }

  # Processing tags
  tags: [

    {
          name: version
          type: {
            source: sst
            sink: client
          }
          path: "F:/share/vulncomponents/nebula/compograph/sst/version"
          noField:false
          fields: [compoid,name,publishtime]
          nebula.fields: [compoid,name,publishtime]
          #_vertexId
          vertex: _vertexId
          batch: 20000
          partition: 60
        }
  ]

  # process edges
  edges1: [
    {
      name: cdc
      type: {
        source: sst
        sink: client
      }
      path: "F:/share/vulncomponents/nebula/compograph/sst/cdc"
      fields: [ dt ]
      nebula.fields: [ dt ]
      #_srcId, _dstId, _rank
      source: _srcId
      target: _dstId
      batch: 20000
      partition: 60
    }
    ,{
        name: cdv
        type: {
          source: sst
          sink: client
        }
        path: "F:/share/vulncomponents/nebula/compograph/sst/cdv"
        fields: [ dt ]
        nebula.fields: [ dt ]
        #_srcId, _dstId, _rank
        source: _srcId
        target: _dstId
        batch: 2000
        partition: 60
   },{
       name: vdv
       type: {
         source: sst
         sink: client
       }
       path: "F:/share/vulncomponents/nebula/compograph/sst/vdv"
       fields: [ dt ]
       nebula.fields: [ dt ]
       #_srcId, _dstId, _rank
       source: _srcId
       target: _dstId
       batch: 2000
       partition: 60
    }
  ]
}
